{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.environment.ac_control.env import ACControl\n",
    "from src.environment.ac_control.agent import Agent\n",
    "from src.environment.ac_control.interaction import behavior_policy_interaction, estimate_policy_interaction\n",
    "from src.environment.interaction_buffer import Buffer\n",
    "\n",
    "from src.ope.data import train_test_split\n",
    "from src.ope.distribution_evaluation import total_variation_distance_score, brier_score\n",
    "from src.ope.ope_evaluation import execute_ope\n",
    "from src.ope.ranking_evaluation import nDCG\n",
    "\n",
    "from src.ope.visualize import vis_multiclass_calibration_curve\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "b_buffer = Buffer()\n",
    "\n",
    "behavior_policy_history = behavior_policy_interaction(\n",
    "    env = ACControl(),\n",
    "    buffer = b_buffer,\n",
    "    policy_name = 0, \n",
    "    columns = ['ID', 'State', 'Action', 'Reward', 'Next_state', 'Behavior_Policy'], \n",
    "    trial_len = 100_000, \n",
    "    model = agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, train_X, train_Y, test_X, test_Y = train_test_split(behavior_policy_history, 'half')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "models = {\n",
    "    'rf_5' : RandomForestClassifier(max_depth=5),\n",
    "    'rf_10' : RandomForestClassifier(max_depth=10),\n",
    "\n",
    "    'knn_30' : KNeighborsClassifier(n_neighbors=30),\n",
    "    'knn_100' : KNeighborsClassifier(n_neighbors=100),\n",
    "\n",
    "    'lr_10' : LogisticRegression(C=10),\n",
    "    'lr_1' : LogisticRegression(C=1),\n",
    "\n",
    "    'rf_10_iso' : CalibratedClassifierCV(RandomForestClassifier(max_depth=10), cv=2, method=\"isotonic\"),\n",
    "    'knn_100_iso' : CalibratedClassifierCV(KNeighborsClassifier(n_neighbors=100), cv=2, method=\"isotonic\"),\n",
    "    'lr_10_iso' : CalibratedClassifierCV(LogisticRegression(C=10), cv=2, method=\"isotonic\")  ,\n",
    "\n",
    "    'rf_sig' : CalibratedClassifierCV(RandomForestClassifier(max_depth=10), cv=2, method=\"sigmoid\"),\n",
    "    'knn_100_sig' : CalibratedClassifierCV(KNeighborsClassifier(n_neighbors=100), cv=2, method=\"sigmoid\"),\n",
    "    'lr_10_sig' : CalibratedClassifierCV(LogisticRegression(C=10), cv=2, method=\"sigmoid\") \n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "vis_multiclass_calibration_curve(\n",
    "    test_dataset = test_dataset,\n",
    "    models = models,\n",
    "    data = (train_X, train_Y, test_X),\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ope_iter = 100\n",
    "n_ope_sample_size = 10_000\n",
    "n_interaction=30_000\n",
    "\n",
    "'''\n",
    "提案手法が良かった\n",
    "\n",
    "n_ope_iter = 50\n",
    "n_ope_sample_size = 5_000\n",
    "n_interaction=10_000\n",
    "\n",
    "n_dcg :  0.8447762970745545 , coef :  0.49711895766580066\n",
    "n_dcg :  0.8447762970745545 , coef :  0.4978606579852835\n",
    "n_dcg :  0.8747248725691102 , coef :  0.34398906419564845\n",
    "n_dcg :  0.8279003362987507 , coef :  0.9992369165923656\n",
    "\n",
    "提案手法が劣る\n",
    "\n",
    "n_ope_iter = 100\n",
    "n_ope_sample_size = 10_000\n",
    "n_interaction=30_000\n",
    "\n",
    "n_dcg :  0.910824379579457 , coef :  0.3323746430513848\n",
    "n_dcg :  0.9089511138678534 , coef :  0.3471672655984594\n",
    "n_dcg :  0.8427266995642954 , coef :  0.26709644913265\n",
    "n_dcg :  0.7323147414714958 , coef :  0.962537869818187\n",
    "'''\n",
    "\n",
    "opes = np.zeros((len(models), n_ope_iter+4))\n",
    "\n",
    "\n",
    "for idx, model_key in enumerate(models):\n",
    "    model = models[model_key]\n",
    "    model.fit(train_X, train_Y)\n",
    "    dist = model.predict_proba(test_X)\n",
    "    \n",
    "    history = estimate_policy_interaction(\n",
    "        env=ACControl(),\n",
    "        buffer=Buffer(),\n",
    "        policy_name=0,\n",
    "        columns=['ID', 'State', 'Action', 'Reward', 'Next_state', 'Behavior_Policy'],\n",
    "        trial_len=n_interaction,\n",
    "        model=model,\n",
    "    )\n",
    "    total_variation_distance = total_variation_distance_score(\n",
    "        test_dataset = test_dataset, \n",
    "        estimate_policy = [d[test_Y[idx]] for idx, d in enumerate(dist)],\n",
    "        coef = 1,\n",
    "    )\n",
    "    brier_score_0_0 = brier_score(\n",
    "        test_dataset = test_dataset,\n",
    "        predict_probs = dist, \n",
    "        thresh = 0.0\n",
    "    )\n",
    "    brier_score_0_5 = brier_score(\n",
    "        test_dataset = test_dataset,\n",
    "        predict_probs = dist, \n",
    "        thresh = 0.5\n",
    "    )\n",
    "    brier_score_1 = brier_score(\n",
    "        test_dataset = test_dataset,\n",
    "        predict_probs = dist, \n",
    "        thresh = 1.0\n",
    "    )\n",
    "    ope_list = execute_ope(\n",
    "        test_dataset = test_dataset,\n",
    "        estimate_policy_history = history,\n",
    "        model = model,\n",
    "        sample_size = n_ope_sample_size,\n",
    "        n_len = n_ope_iter,\n",
    "        model_type = 'sklearn',\n",
    "        v_estimator = 'IPS',\n",
    "        error_function = 'relative',\n",
    "    )\n",
    "    opes[idx, 0] = total_variation_distance\n",
    "    opes[idx, 1] = brier_score_0_0\n",
    "    opes[idx, 2] = brier_score_0_5\n",
    "    opes[idx, 3] = brier_score_1\n",
    "    opes[idx, 4:] = ope_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = np.zeros((len(models), 5))\n",
    "\n",
    "def get_rank(arr: np.array):\n",
    "    return np.argsort(np.argsort(arr))\n",
    "\n",
    "ranks[:, 0] = get_rank(np.mean(opes[:, 4:], axis=1))\n",
    "ranks[:, 1] = get_rank(opes[:, 0])\n",
    "ranks[:, 2] = get_rank(opes[:, 1])\n",
    "ranks[:, 3] = get_rank(opes[:, 2])\n",
    "ranks[:, 4] = get_rank(opes[:, 3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ope = np.mean(opes[:, 4:], axis=1)\n",
    "\n",
    "for idx in np.arange(4):\n",
    "    idx = idx + 1\n",
    "    print(\n",
    "        'n_dcg : ', nDCG(ranks[:, 0], ranks[:, idx]), ', coef : ', np.min(np.corrcoef(opes[:, idx], mean_ope))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "212f92abc0e2e59dde7de5ba32801ef99667000031d48df25f519fe1fb7790fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
