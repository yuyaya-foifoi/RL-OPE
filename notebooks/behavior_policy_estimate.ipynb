{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.environment.ac_control.env import ACControl\n",
    "from src.environment.ac_control.agent import Agent\n",
    "from src.environment.ac_control.interaction import behavior_policy_interaction, estimate_policy_interaction\n",
    "from src.environment.interaction_buffer import Buffer\n",
    "\n",
    "from src.ope.data import train_test_split\n",
    "from src.ope.distribution_evaluation import eval_policy_distance\n",
    "from src.ope.ope_evaluation import execute_ope\n",
    "from src.ope.visualize import visualize_error_per_distance\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "b_buffer = Buffer()\n",
    "\n",
    "behavior_policy_history = behavior_policy_interaction(\n",
    "    env = ACControl(),\n",
    "    buffer = b_buffer,\n",
    "    policy_name = 0, \n",
    "    columns = ['ID', 'State', 'Action', 'Reward', 'Next_state', 'Behavior_Policy'], \n",
    "    trial_len = 30_000, \n",
    "    model = agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, train_X, train_Y, test_X, test_Y = train_test_split(behavior_policy_history, 'half')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(),\n",
    "    CalibratedClassifierCV(RandomForestClassifier(), cv=2, method=\"isotonic\"),\n",
    "    #CalibratedClassifierCV(RandomForestClassifier(), cv=2, method=\"sigmoid\"),\n",
    "    CalibratedClassifierCV(KNeighborsClassifier(), cv=2, method=\"isotonic\"),\n",
    "    #CalibratedClassifierCV(KNeighborsClassifier(), cv=2, method=\"sigmoid\"),\n",
    "    CalibratedClassifierCV(LogisticRegression(), cv=2, method=\"isotonic\"),\n",
    "    #CalibratedClassifierCV(LogisticRegression(), cv=2, method=\"sigmoid\"),\n",
    "    \n",
    "]\n",
    "\n",
    "model_name = [\n",
    "    'RF',\n",
    "    'KN',\n",
    "    'LR',\n",
    "    'RF_isotonic',\n",
    "    #'RF_sigmoid',\n",
    "    'KN_isotonic',\n",
    "    #'KN_sigmoid',\n",
    "    'LR_isotonic',\n",
    "    #'LR_sigmoid',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opes = np.zeros((len(models), 11))\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    model.fit(train_X, train_Y)\n",
    "    dist = model.predict_proba(test_X)\n",
    "    \n",
    "    history = estimate_policy_interaction(\n",
    "        env=ACControl(),\n",
    "        buffer=Buffer(),\n",
    "        policy_name=0,\n",
    "        columns=['ID', 'State', 'Action', 'Reward', 'Next_state', 'Behavior_Policy'],\n",
    "        trial_len=1_000,\n",
    "        model=model,\n",
    "    )\n",
    "    policy_distace = eval_policy_distance(\n",
    "        test_dataset = test_dataset, \n",
    "        estimate_policy = [d[test_Y[idx]] for idx, d in enumerate(dist)],\n",
    "        coef = 1,\n",
    "        distace_func = 'total'\n",
    "    )\n",
    "    ope_list = execute_ope(\n",
    "        test_dataset = test_dataset,\n",
    "        estimate_policy_history = history,\n",
    "        model = model,\n",
    "        sample_size = 3000,\n",
    "        n_len = 10,\n",
    "        model_type = 'sklearn',\n",
    "        v_estimator = 'IPS',\n",
    "        error_function = 'relative',\n",
    "    )\n",
    "    opes[idx, 0] = policy_distace\n",
    "    opes[idx, 1:] = ope_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_error_per_distance(opes, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "212f92abc0e2e59dde7de5ba32801ef99667000031d48df25f519fe1fb7790fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
